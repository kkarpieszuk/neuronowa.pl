---
title: Anthropic mówi o powstrzymaniu dużego ataku, ale mało kto w to wierzy
published: 2025-11-16 17:22
tags:
  - claude
  - Anthropic
---
Wczoraj firma #Anthropic, twórca Claude, [poinformował](https://assets.anthropic.com/m/ec212e6566a0d47/original/Disrupting-the-first-reported-AI-orchestrated-cyber-espionage-campaign.pdf) świat o powstrzymaniu dużego zautomatyzowanego ataku na wiele firm. 

Atak miał przebiegać dość standardowo: włamywacze penetrowali strony i usługi w sieci za pomocą dostępnego oprogramowania do pentestów, próbując włamań na znane, nie załatane podatności w popularnych programach.

Tym razem miała być jednak pewne różnica: atak był prowadzony niemal kompletnie automatycznie z użyciem agentów AI. Sztuczna inteligencja automatycznie wyszukiwarka ofiary, analizowała używane przez nie oprogramowanie, próbowała włamać się licząc że znane podatności wciąż są nie załatane lub po prostu metodą brute force starała się zgadnąć hasła.

Modele AI mają wbudowane zabezpieczenia przed użyciem ich do celów niezgodnych z prawem, ale włamywacze obeszli to tak konstruując zapytania (prompty) by wyglądało to jakby byli naukowcami testujący mi skuteczność narzędzi pentestujacych, w słusznych bo naukowych celów. 

Anthropic rozpoznało ten atak (jako pochodzący z Chin) i zbanowało adresy IP z których atak był prowadzony.

[Komentarze w sieci](https://djnn.sh/posts/anthropic-s-paper-smells-like-bullshit/) są takie, że raport zawiera zbyt mało szczegółów. Bardziej wygląda jak treść marketingowa, mająca na celu przyciągnięcie czytających, publicity a więc i większą rozpoznawalność firmy. Mój komentarz jest taki, że czytając raport ciężko nie odnieść wrażenia że on sam był pisany z użyciem AI (ale to już coraz częściej standard).