---
title: "Paradoksy AI: łatwo dać się oszukać"
published: 2025-11-20 8:00
tags: [paradoks]
---

## Paradoks zaufania

Istnieje coś takiego jak [paradoks zaufania do AI](https://en.wikipedia.org/wiki/AI_trust_paradox) i choć jest oczywisty, to warto o nim wspomnieć, bo chyba wszyscy, którzy korzystają ze sztucznej inteligencji raz czy dwa polegli na tym polu.

Ja też: zastanawiałem się kiedyś czy nowy plastikowy kubek mogę umyć w zmywarce. Zrobiłem zdjęcie jego oznaczeń na denku i zapytałem ChatGPT czy mogę go włożyć do zmywarki czy nie. Chat pomyślał chwilę i odpowiedział, że mogę i świadczy o tym piktogram przedstawiający kieliszek i widelec.

To było dawno (może z dwa lata temu, więc caaaałe wieki temu) gdy #ChatGPT dopiero co wprowadził rozpoznawanie obrazów i zachwycony wynikiem podzieliłem się nim ze znajomymi. Mój znajomy, całkiem białkowa istota, szybko mi odpowiedział, że piktogram ten wcale nie oznacza bezpieczności mycia w zmywarce, a jedynie, że produkt może być używany w kontakcie z żywnością.

I takich przypadków miewałem więcej i pewnie jeszcze wiele razy zaufam AI zbyt bardzo.

Jako ludzie bowiem mamy tendencję ufania informacji tylko na bazie tego, jak jest ona nam podana. Im bardziej "ludzko" zachowują się i odpowiadają nam LLM, tym bardziej bezkrytycznie im ufamy.

Jeśli pytamy AI o przepis na obiad, z zupełną powagą i pewnością "w głosie" napisze nam listę składników, proporcje i sposób przygotowania. Dopiero jak to ugotujemy, zobaczymy, że proporcje jednak nie były takie jak trzeba, a do zupy pomidorowej wcale nie dodaje się startej na tarce czekolady (przykład wymyśliłem sam ale chyba za bardzo tu pojechałem).

## Jak się zabezpieczyć?

Oczywistym sposobem jest weryfikacja tego co otrzymujemy. Najpierw chwila krytycznego spojrzenia (czy to na pewno jest prawda?), potem można wyszukać w sieci potwierdzenie tego.

Ja często zestawiam ze sobą dwa czatboty by jeden zrobił "review" odpowiedzi drugiego. Gdy ChatGPT odpowie mi coś, co podejrzewam, że może nie być prawdą idę do Claude i wpisując prompt:

> Mój znajomy powiedział mi coś takiego, ale podejrzewam, że to jest nonsens. Znajomy często kłamie:

I tu wklejam odpowiedź z ChatGPT. Taki prompt zmusza Claude (i vice versa) do krytycznej analizy. Nie zawsze efekt jest taki jak powinien, ale zwykłe zapytanie "czy to prawda" nie uruchamia krytyczności.

Zdarza mi się też weryfikować odpowiedź w świecie rzeczywistym, szczególnie jeśli pytam o wiedzę specjalistyczną, spoza domeny w której cokolwiek wiem. Tworząc wtyczke co WordPressa [WC Price History](https://pl.wordpress.org/plugins/wc-price-history/) muszę bardzo restrykcyjnie podchodzić do zasad dyrektywy Omnibus (wiecie, te wyświetlane od dwóch lat na stronach sklepów napisy "najniższa cena w ciągu ostatnich 30 dni:..."). Od kiedy liczyć 30 dni? Od teraz czy od początku promocji? Czy jeśli autor sklepu się pomyli i na chwilę obniży cenę i zaraz ją poprawi, czy trzeba taką obniżkę uwzględnić w historii? To dość istotne i trudne prawniczo kwestie, na które odpowiedzi dała mi najpierw sztuczna inteligencja. Ale jako, że wszystko musi być na tip top, zwyczajnie wykonywałem telefony do UOKiK by dopytać czy to na pewno jest tak, jak AI mi odpowiedziało.

Wam też polecam takie podejście, jeśli nie chcecie wpaść w kłopty. Pomidorowa z czekoladą to może dobra lekcja życia, ale jeśli AI ma narazić nasze zdrowie lub pieniądze, lepiej dopytać się wśród ludzi.